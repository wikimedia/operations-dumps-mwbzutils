What is this?

It is a tiny suite of utilities that hapless WMF employees use to massage the
XML dump files so that we can produce them on a more regular basis.

More specifically, they allow us to do various things with bz2 files
quickly instead of requiring a serial read/decompress of the file.  Some
of these files range from 2 to 30 GB in size, so serial access is too slow.

The files bz2libfuncs.c, bzlib.h and bzlib_private.h are taken from bzip2/libbzip2
version 1.0.6 of 6 September 2010 (Copyright (C) 1996-2010 Julian Seward
<jseward@bzip.org>) and as such their copyright license is in the file
LICENSE_BZ; all other files in the package are released under the GPL,
see the file COPYING for details.

Scripts:

check_bz2_pagerange.py - Checks that the first and last page of a bz2 content
                         checkpoint filename match the contents in the file,
			 i.e. the first page id in the name is the first page
			 id contained in the file, and the same for the last
			 page id. This uses the MediaWiki api as well as
			 the getlastidinbz2xml utility for which see below.

show_byte_aligned_crcs.py - Find all byte-aligned bz2 blocks in a file and
  			 show their offsets, crcs and the combined crc
			 of the blocks up to that point. Blocks are found
			 by looking for the start of block marker, but
			 are not decompressed to verify that they are valid.
			 There is a small possibility that a marker could
			 exist naturally in the middle of a block.

split_bz2.py          -  Uses the dumpbz2filefromoffset and writeuptopageid
                         utilities described below, to split an xml dump bz2
			 file into smaller ones.

Utilities:

appendbz2             - Reading from stdin, writes bz2-compressed output with
                        bz2 footer but no bz2 header, with a combined crc
		        dependent on an initial combined crc argument and
			the crc of the blocks dependent on the data from stdin.
			        This can be used to write data to append to a bz2
                        file truncated at a byte-aligned bz2 block.

checkforbz2footer     - Tests to see if the bz2 file specified on the command line
		        has a bz2 footer (if it does it is likely to be intact).
			Exits with 0 if found, 1 otherwise.

dumpbz2filefromoffset - Uncompresses the file from the first bz2 block found after
		        the specified offset, and dumps the results to stdout.
                        This will first look for and dump the <mediawiki> header,
			up to and including the </siteinfo> tag; then it will
			find the first <page> tag in the first bz2 block after
			the specified output and dump the contents from that point
			on.

dumplastbz2block      - Finds the last bz2 block marker in a file and dumps whatever
		        can be decompressed after that point;  the header of the file
			must be intact in order for any output to be produced. This
			will produce output for truncated files as well, as long as
			there is "enough" data after the bz2 block marker.
			Exits with 0 if decompression of some data can be done,
			1 if decompression fails, and -1 on error.

findpageidinbz2xml    - Given a bzipped and possibly truncated file, and a page id,
		        hunt for the page id in the file; this assumes that the
			bz2 header is intact and that page ids are steadily increasing
			throughout the file.  It writes the offset of the relevant block
			(from beginning of file) and the first pageid found in that block,
			to stdout. Format of output:
			     position:xxxxx pageid:nnn
			It exits with 0 on success, -1 on error.

getlastidinbz2xml     - Given a bzipped xml content file and a page or rev id and the
                        type (either 'page' or 'rev'), return the last such id in the
			xml file.

recompresszml         - Reads an xml stream of pages and writes multiple bz2 compressed
		        streams, concatenated, to stdout, with the specified number of
		        pages per stream. The mediawiki site info header is in its
			own bz2 stream.  Each stream can be extracted as a separate file
			by an appropriate tool, checking for the byte-aligned string "BZh91AY&SY"
			and a following <page> tag (after uncompressing the first chunk
			of data after that string).  Alternatively, a tool can seek to
			the location of one of the streams in order to find a particular
			page.  An index of file-offset:page-id:page-title lines
			is written to a specified file if desired; the index file will be
			bz2 compressed if the filename given ends with .bz2.

revsperpage           - Display information about the revisions (count, length, max length)
                        for each page read from a MediaWiki XML input stream

showcrcs              - Given a bzip2 compressed file, extracts the byte offsets and crcs
                        for each block and for the entire file, and displays them; it can
			also try to compute the file crc from the block crcs and display that.
			Blocks are found by looking for the start of block marker, but
			are not decompressed to verify that they are valid. There is a small
			possibility that a marker could exist naturally in the middle of a block.

Library routines:

mwbz2lib.c            - various utility functions (bitmasks, shifting and comparing bytes,
	                setting up bz2 files for decompression, etc)

External library routines:

bz2libfuncs.c         - the BZ2_bzDecompress() routine, modified so that it does not do
		      	a check of the cumulative CRC (since we read from an arbitrary
			point in most of these files, we won't have a cumulative CRC
			that makes any sense).  It's a one line fix but it requires
			unRLE_obuf_to_output_FAST() which is marked static in the original
			library, so that's in here too.

